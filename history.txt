import pandas as pd 
import numpy as np 
import sklearn as sk 
import seaborn as sns 
import matplotlib.pyplot as plt
import matplotlib
#from imp import reload

#reload(matplotlib)
#matplotlib.use('agg')

import matplotlib.pyplot as plt
#plt.interactive(False)
plt.ioff()
import pandas as pd 
import numpy as np 
import sklearn as sk 
import seaborn as sns 
import matplotlib.pyplot as plt
import matplotlib
#from imp import reload

#reload(matplotlib)
#matplotlib.use('agg')

import matplotlib.pyplot as plt
#plt.interactive(False)
plt.ioff()
%matplotlib inline
bank_data = pd.read_csv("bank-additional/bank-additional-full.csv", sep=";")
bank_data_copy = bank_data.copy()
bank_data_copy.info()
bank_data_copy['y_binary'] = bank_data_copy.y.map(dict(yes=1, no=0));
bank_data_copy.head()
bank_data_copy.age.median()
plt.style.use('seaborn-whitegrid')
bank_data_copy.hist(bins=20, figsize=(14,10));
bank_data_copy.describe()
labels = 'Did not open term', 'Opened term'
fig, ax = plt.subplots(1, 2, figsize = (16, 8))

bank_data_copy.y.value_counts().plot.pie(explode=[0,0.25],
                                         autopct ='%1.2f%%', ax = ax[0], shadow = True, labels = labels,
                                         fontsize = 12, startangle = 135)
plt.suptitle('Information on term subscriptions', fontsize = 20)

df = bank_data_copy.groupby(['education','y']).size().groupby(level=0).apply(
    lambda x: x/bank_data_copy.shape[0]).unstack().plot(kind='bar', ax = ax[1], stacked = True)

ax[1].set(ylabel = 'Percentage of term openers by level of education')
ax[1].set(xlabel = 'Education level')
ax[1].legend(labels)
plt.show();
plt.close()
fig, ax = plt.subplots(1, 2, figsize = (16, 8))
plt.suptitle('Information on Term Subscription 2', fontsize = 20)

df = bank_data_copy.groupby(['age', 'y']).size().groupby(level=0, squeeze=True).apply(lambda x: x/bank_data_copy.shape[0]).unstack().plot(kind='bar', ax=ax[0], stacked=True)

ax[0].set(ylabel = 'Percentage of term openers by age')
ax[0].set(xlabel = 'Age')
ax[0].locator_params(axis= 'x', nbins = 60)
ax[0].legend(labels)

df1 = bank_data_copy.groupby(['marital', 'y']).size().groupby(level = 0).apply(lambda x: x/bank_data_copy.shape[0]).unstack().plot(kind='bar', ax=ax[1])

ax[1].set(ylabel = 'Percentage of term openers by marital status')
ax[1].set(xlabel = 'Marital status')
ax[1].tick_params(axis='x', labelrotation=45)
ax[1].legend(labels)

plt.show();
df = bank_data_copy.groupby(['age', 'y']).size().groupby(level=0, squeeze=True).apply(lambda x: x/bank_data_copy.shape[0]).unstack()
df.head()
%matplotlib inline
sns.set()
plt.style.use('seaborn-whitegrid')
bank_data_copy.hist(bins=20, figsize=(14,10));
fig, ax = plt.subplots(1, 2, figsize = (16, 8))

bank_data_copy.y.value_counts().plot.pie(explode=[0,0.25],
                                         autopct ='%1.2f%%', ax = ax[0], shadow = True, labels = labels,
                                         fontsize = 12, startangle = 135)
plt.suptitle('Information on term subscriptions', fontsize = 20)

df = bank_data_copy.groupby(['education','y']).size().groupby(level=0).apply(
    lambda x: x/bank_data_copy.shape[0]).unstack().plot(kind='bar', ax = ax[1], stacked = True)

ax[1].set(ylabel = 'Percentage of term openers by level of education')
ax[1].set(xlabel = 'Education level')
ax[1].legend(labels)
plt.show();
fig, ax = plt.subplots(1, 2, figsize = (16, 8))
plt.suptitle('Information on Term Subscription 2', fontsize = 20)

df = bank_data_copy.groupby(['age', 'y']).size().groupby(level=0, squeeze=True).apply(lambda x: x/bank_data_copy.shape[0]).unstack().plot(kind='bar', ax=ax[0], stacked=True)

ax[0].set(ylabel = 'Percentage of term openers by age')
ax[0].set(xlabel = 'Age')
ax[0].locator_params(axis= 'x', nbins = 60)
ax[0].legend(labels)

df1 = bank_data_copy.groupby(['marital', 'y']).size().groupby(level = 0).apply(lambda x: x/bank_data_copy.shape[0]).unstack().plot(kind='bar', ax=ax[1])

ax[1].set(ylabel = 'Percentage of term openers by marital status')
ax[1].set(xlabel = 'Marital status')
ax[1].tick_params(axis='x', labelrotation=45)
ax[1].legend(labels)

plt.show();
df = bank_data_copy.groupby(['age', 'y']).size().groupby(level=0, squeeze=True).apply(lambda x: x/bank_data_copy.shape[0]).unstack()
df.head()
df = bank_data_copy.groupby(['age', 'y']).size().groupby(level=0, squeeze=True).apply(lambda x: x/bank_data_copy.shape[0]).unstack()
df.head(50)
df = bank_data_copy.groupby(['age', 'y']).size().groupby(level=0, squeeze=True).apply(lambda x: x/bank_data_copy.shape[0])
df.head(50)
df = bank_data_copy.groupby(['age', 'y']).size().groupby(level=0, squeeze=True).apply(lambda x: x/bank_data_copy.shape[0]).unstack()
df.head(50)
df = bank_data_copy.groupby(['age', 'y']).size().groupby(level=0, squeeze=True).apply(lambda x: x/bank_data_copy.shape[0]).unstack()
df.head(20)
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
dependent_var = bank_data_copy['y_binary']
encoded_df = bank_data_copy.copy()
encoded_df.drop(['y', 'y_binary'], axis=1, inplace=True)
# Apply the label encoder to the data in the dataframe
encoded_df = encoded_df.apply(encoder.fit_transform)
# Do a sanity check
# (These are important to do throughout, as well as taking notes)
encoded_df.head()
# Type check the data
encoded_df.info()
# Check the descriptive statistics
encoded_df.describe()
# Make a correlation matrix

correlation_df = pd.concat([encoded_df, dependent_var], axis=1)
plt.figure(figsize=(17,15))
cor = correlation_df.corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.tick_params(axis='x', labelrotation=25)
plt.show();
# Step 1: find features that are highly correlated with y

cor_target = abs(cor['y_binary']) # the absolute value of the target variable's correlation with each feature

relevant_features = cor_target[cor_target > 0.2] # Use boolean indexing to find features that have greater than twenty percent correlation with y
relevant_features
rel_feat = relevant_features.index.tolist()
rel_feat.remove('y_binary')
from itertools import combinations
from IPython.display import display_html
dfs = []
for pair in combinations(rel_feat, 2):
    a, b = pair
    df = encoded_df[[a, b]].corr()
    c = df.to_numpy()
    c = np.fliplr(c).diagonal()[0]
    parity = 'INVERSE' if c < 0 else 'POSITIVE'
    dfs.append(df)
    if abs(c) > 0.2:
        display_html(df)
        print('\n')
        print("{} and {} have {} percent correlation.".format(a, b, round(abs(c), 3)*100))
        print("They are {}LY correlated.".format(parity))
        print("{}'s correlation with y: {}%".format(a, round(relevant_features[a], 3)*100))
        print("{}'s correlation with y: {}%".format(b, round(relevant_features[b], 3)*100))
        print('\n')
dfs = []
for pair in combinations(rel_feat, 2):
    a, b = pair
    df = encoded_df[[a, b]].corr()
    c = df.to_numpy()
    c = np.fliplr(c).diagonal()[0]
    parity = 'INVERSE' if c < 0 else 'POSITIVE'
    dfs.append(df)
    if abs(c) > 0.2:
        display_html(df)
        print('\n')
        print("{} and {} have {}% correlation.".format(a, b, round(abs(c), 3)*100))
        print("They are {}LY correlated.".format(parity))
        print("{}'s correlation with y: {}%".format(a, round(relevant_features[a], 3)*100))
        print("{}'s correlation with y: {}%".format(b, round(relevant_features[b], 3)*100))
        print('\n')
dfs = []
for pair in combinations(rel_feat, 2):
    a, b = pair
    df = encoded_df[[a, b]].corr()
    c = df.to_numpy()
    c = np.fliplr(c).diagonal()[0]
    parity = 'INVERSE' if c < 0 else 'POSITIVE'
    dfs.append(df)
    if abs(c) > 0.2:
        display_html(df)
        print('\n')
        print("{} and {} have {}% correlation.".format(a, b, round(c, 3)*100))
        print("They are {}LY correlated.".format(parity))
        print("{}'s correlation with y: {}%".format(a, round(relevant_features[a], 3)*100))
        print("{}'s correlation with y: {}%".format(b, round(relevant_features[b], 3)*100))
        print('\n')
encoded_df.drop(['age', 'housing', 'loan', 'default', 'day_of_week'], axis=1, inplace=True) # emp.var.rate, previous
encoded_df.head()
# Take 80% of data for training
print(bank_data_copy.shape)
train_len = int(0.8*bank_data_copy.shape[0])
train_x, train_y = encoded_df[:train_len], dependent_var[:train_len]
test_x, test_y = encoded_df[train_len:], dependent_var[train_len:]
from sklearn.linear_model import LogisticRegression
# regularization is applied by default
# For ‘multinomial’ the loss minimised is the multinomial loss fit across the entire probability distribution

log_reg = LogisticRegression(solver = 'lbfgs',    # 'lbfgs' solver for multinomial logistic regression
                             penalty='l2',        #  ridge regression adds a penalty based on the sum of the squared weights, providing larger (+/-) weights resulting in a greater penalty
                             max_iter=10000)
log_reg_trained = log_reg.fit(train_x, train_y)
print(f"Training accuracy: {log_reg.score(train_x, train_y)}")
pred = log_reg.predict(test_x)
print(f"Test accuracy: {sk.metrics.accuracy_score(test_y, pred)}")
for item in sorted(zip(encoded_df.columns.tolist(), log_reg.coef_[0]), reverse=True):
    print(f"Coefficient for '{item[0]}' is {round(item[1], 3)}")
from sklearn.tree import DecisionTreeClassifier
dec_tree = DecisionTreeClassifier()
tree_model = dec_tree.fit(train_x, train_y)
print(f"Training accuracy for decision tree: {dec_tree.score(train_x, train_y)}")
pred_1 = dec_tree.predict(test_x)
print(f"Test accuracy for decision tree: {sk.metrics.accuracy_score{test_y, pred_1}")
print(f"Test accuracy for decision tree: {sk.metrics.accuracy_score{test_y, pred_1)}")
print(f"Test accuracy for decision tree: {sk.metrics.accuracy_score(test_y, pred_1)}")
print(f"Test accuracy for decision tree: {sk.metrics.accuracy_score(pred_1, test_y)}")
print(f"Test accuracy for decision tree: {sk.metrics.accuracy_score(test_y, pred_1)}")
from aix360.algorithms.lime import LimeTabularExplainer
class_names = [0, 1]
log_lime_explainer = LimeTabularExplainer(train_x.values, class_names = class_names, feature_names = train_x.columns)
sample_idx = 0
sample_observation = train_x.values[idx]
sample_idx = 0
sample_observation = train_x.values[sample_idx]
print(f"Explanation for class {class_names[0]}")
print("\n".join(map(str, exp_log.as_list(label = 0))))

print(f"Explanation for class {class_names[1]}")
print("\n".join(map(str, exp_log.as_list(label = 1))))
print(f"The predicted class for observation #{sample_idx} is {log_reg_trained.predict_proba([sample_observation])}")
print(f"The true class is {train_y.loc[sample_idx]}")
idx = 1120
exp_log = log_lime_explainer.explain_instance(train_x.values[idx],
                                              log_reg_trained.predict_proba,
                                              num_features=6,
                                              labels=class_names)
print(f"Explanation for class {class_names[0]}")
print("\n".join(map(str, exp_log.as_list(label = 0))))

print(f"Explanation for class {class_names[1]}")
print("\n".join(map(str, exp_log.as_list(label = 1))))
log_reg_exp.show_in_notebook()
exp_log.show_in_notebook()
from aix360.metrics import faithfulness_metric, monotonicity_metric
idx = 0
predicted_class = log_reg.predict(test_x.values[idx].reshape(1, -1))[0]

local_explanation = exp_log.local_exp[predicted_class]
map_ = exp_log.as_map()
x = test_x.values[idx]
coefs = np.zeros[x.shape[0]]

for v in local_explanation:
    coefs[v[0]] = v[1]

base = np.zeros(x.shape[0])

print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
predicted_class = log_reg.predict(test_x.values[idx].reshape(1, -1))[0]

local_explanation = exp_log.local_exp[predicted_class]
map_ = exp_log.as_map()
x = test_x.values[idx]

x
#coefs = np.zeros[x.shape[0]]
#
#for v in local_explanation:
#    coefs[v[0]] = v[1]
#
#base = np.zeros(x.shape[0])
#
#print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
#print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
predicted_class = log_reg.predict(test_x.values[idx].reshape(1, -1))[0]

local_explanation = exp_log.local_exp[predicted_class]
map_ = exp_log.as_map()
x = test_x.values[idx]

x.shape
#coefs = np.zeros[x.shape[0]]
#
#for v in local_explanation:
#    coefs[v[0]] = v[1]
#
#base = np.zeros(x.shape[0])
#
#print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
#print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
predicted_class = log_reg.predict(test_x.values[idx].reshape(1, -1))[0]

local_explanation = exp_log.local_exp[predicted_class]
map_ = exp_log.as_map()
x = test_x.values[idx]

x.shape[0]
#coefs = np.zeros[x.shape[0]]
#
#for v in local_explanation:
#    coefs[v[0]] = v[1]
#
#base = np.zeros(x.shape[0])
#
#print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
#print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
predicted_class = log_reg.predict(test_x.values[idx].reshape(1, -1))[0]

local_explanation = exp_log.local_exp[predicted_class]
map_ = exp_log.as_map()
x = test_x.values[idx]

coefs = np.zeros(x.shape[0])

for v in local_explanation:
    coefs[v[0]] = v[1]

base = np.zeros(x.shape[0])

print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
[LimeTabularExplainer](https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular)
idx = 1120
predicted_class = log_reg.predict(test_x.values[idx].reshape(1, -1))[0]

local_explanation = exp_log.local_exp[predicted_class]
map_ = exp_log.as_map()
x = test_x.values[idx]

coefs = np.zeros(x.shape[0])

for v in local_explanation:
    coefs[v[0]] = v[1]

base = np.zeros(x.shape[0])

print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
idx = 11
predicted_class = log_reg.predict(test_x.values[idx].reshape(1, -1))[0]

local_explanation = exp_log.local_exp[predicted_class]
map_ = exp_log.as_map()
x = test_x.values[idx]

coefs = np.zeros(x.shape[0])

for v in local_explanation:
    coefs[v[0]] = v[1]

base = np.zeros(x.shape[0])

print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
idx = 1
predicted_class = log_reg.predict(test_x.values[idx].reshape(1, -1))[0]

local_explanation = exp_log.local_exp[predicted_class]
map_ = exp_log.as_map()
x = test_x.values[idx]

coefs = np.zeros(x.shape[0])

for v in local_explanation:
    coefs[v[0]] = v[1]

base = np.zeros(x.shape[0])

print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
idx = 10
predicted_class = log_reg.predict(test_x.values[idx].reshape(1, -1))[0]

local_explanation = exp_log.local_exp[predicted_class]
map_ = exp_log.as_map()
x = test_x.values[idx]

coefs = np.zeros(x.shape[0])

for v in local_explanation:
    coefs[v[0]] = v[1]

base = np.zeros(x.shape[0])

print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
class_names = [0, 1]
tree_lime_explainer = LimeTabularExplainer(train_x.values, class_names = class_names, feature_names = train_x.columns)
# Select data points to inspect for our models
sample_idx = 0
sample_observation = train_x.values[sample_idx]

instance_idx = 1120
def print_model_predictions(model):
    print(f"The predicted class for observation #{sample_idx} is {model.predict_proba([sample_observation])}")
    print(f"The true class is {train_y.loc[sample_idx]}")
print_model_predictions(log_reg_trained)
class ModelExplainer:
    def __init__(self, model, train_x, class_names, num_features):
        self.model = model
        self.train_x = train_x
        self.class_names = class_names
        self.num_features = num_features
        self.lime_explainer = LimeTabularExplainer(self.train_x.values, class_names = self.class_names, feature_names = self.train_x.columns)
        self.instance_idx = None

    def get_exp(self, instance_idx):
        self.exp = self.lime_explainer.explain_instance(self.train_x.values[instance_idx],
                                                       self.model.predict_proba,
                                                       num_features=self.num_features,
                                                       labels=self.class_names)
        self.instance_idx = instance_idx
    
    def explain_one(self, instance_idx, print_stats=True):
        if self.instance_idx == instance_idx: 
            exp = self.exp
        else:
            exp = self.get_exp(instance_idx)
            self.instance_idx = instance_idx
        

        if print_stats:
            print(f"Explanation for class {self.class_names[0]}")
            print("\n".join(map(str, exp.as_list(label = 0))))

            print(f"Explanation for class {self.class_names[1]}")
            print("\n".join(map(str, exp.as_list(label = 1))))
            self.instance_idx=instance_idx

    def show_exp(self, instance_idx):
        try:
            self.exp.show_in_notebook()
        except:
            print("Instantiate a local model first")

    def evaluate_lime(self, instance_idx):
        if self.instance_idx == instance_idx: 
            exp = self.exp
        else:
            exp = self.get_exp(instance_idx)
            self.instance_idx = instance_idx

        predicted_class = self.model.predict(test_x.values[idx].reshape(1, -1))[0]

        local_explanation = exp.local_exp[predicted_class]
        map_ = exp.as_map()
        x = test_x.values[idx]

        coefs = np.zeros(x.shape[0])

        for v in local_explanation:
            coefs[v[0]] = v[1]

        base = np.zeros(x.shape[0])

        print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
        print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
me = ModelExplainer(train_x, class_names=[0,1], num_features=6)
me = ModelExplainer(train_x=train_x, class_names=[0,1], num_features=6)
me = ModelExplainer(train_x=train_x, model=dec_tree, class_names=[0,1], num_features=6)
me.explain_one(0)
class ModelExplainer:
    def __init__(self, train_x, model, class_names, num_features):
        self.model = model
        self.train_x = train_x
        self.class_names = class_names
        self.num_features = num_features
        self.lime_explainer = LimeTabularExplainer(self.train_x.values, class_names = self.class_names, feature_names = self.train_x.columns)
        self.instance_idx = None

    def get_exp(self, instance_idx):
        self.exp = self.lime_explainer.explain_instance(self.train_x.values[instance_idx],
                                                       self.model.predict_proba,
                                                       num_features=self.num_features,
                                                       labels=self.class_names)
        self.instance_idx = instance_idx
        return self.exp


    
    def explain_one(self, instance_idx, print_stats=True):
        if self.instance_idx == instance_idx: 
            exp = self.exp
        else:
            exp = self.get_exp(instance_idx)
            self.instance_idx = instance_idx
        

        if print_stats:
            print(f"Explanation for class {self.class_names[0]}")
            print("\n".join(map(str, exp.as_list(label = 0))))

            print(f"Explanation for class {self.class_names[1]}")
            print("\n".join(map(str, exp.as_list(label = 1))))
            self.instance_idx=instance_idx

    def show_exp(self, instance_idx):
        try:
            self.exp.show_in_notebook()
        except:
            print("Instantiate a local model first")

    def evaluate_lime(self, instance_idx):
        if self.instance_idx == instance_idx: 
            exp = self.exp
        else:
            exp = self.get_exp(instance_idx)
            self.instance_idx = instance_idx

        predicted_class = self.model.predict(test_x.values[idx].reshape(1, -1))[0]

        local_explanation = exp.local_exp[predicted_class]
        map_ = exp.as_map()
        x = test_x.values[idx]

        coefs = np.zeros(x.shape[0])

        for v in local_explanation:
            coefs[v[0]] = v[1]

        base = np.zeros(x.shape[0])

        print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
        print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
me = ModelExplainer(train_x=train_x, model=dec_tree, class_names=[0,1], num_features=6)
me.explain_one(0)
me.explain_one(1)
me.explain_one(2)
tree_lime_explainer = ModelExplainer(train_x=train_x, model=dec_tree, class_names=[0,1], num_features=6)
tree_lime_explainer.explain_one(2)
idx = 0
predicted_class = log_reg.predict(test_x.values[idx].reshape(1, -1))[0]

local_explanation = exp_log.local_exp[predicted_class]
map_ = exp_log.as_map()
x = test_x.values[idx]

coefs = np.zeros(x.shape[0])

for v in local_explanation:
    coefs[v[0]] = v[1]

base = np.zeros(x.shape[0])

print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
log_reg_explaainer = ModelExplainer(train_x=train_x, model=log_reg_trained, class_names=class_names, num_features=6)
tree_lime_explainer.explain_one(0)
log_reg_explainer.explain_one(0)
log_reg_explainer = ModelExplainer(train_x=train_x, model=log_reg_trained, class_names=class_names, num_features=6)
log_reg_explainer.explain_one(0)
tree_lime_explainer.show_exp()
tree_lime_explainer.show_exp(0)
log_reg_explainer.show_exp(0)
tree_lime_explainer = ModelExplainer(train_x=train_x, model=dec_tree, class_names=class_names, num_features=6)
log_reg_explainer = ModelExplainer(train_x=train_x, model=log_reg_trained, class_names=class_names, num_features=6)
tree_lime_explainer = ModelExplainer(train_x=train_x, model=dec_tree, class_names=class_names, num_features=6)
log_reg_explainer = ModelExplainer(train_x=train_x, model=log_reg_trained, class_names=class_names, num_features=6)
tree_lime_explainer.explain_one(idx)
log_reg_explainer.explain_one(idx)
tree_lime_explainer.show_exp(0)
log_reg_explainer.show_exp(0)
tree_lime_explainer.show_exp(idx)
log_reg_explainer.show_exp(idx)
tree_lime_explainer.show_exp(idx+1)
tree_lime_explainer.show_exp(idx+10)
tree_lime_explainer.explain_one(10)
tree_lime_explainer.explain_one(0)
tree_lime_explainer.explain_one(3)
tree_lime_explainer = ModelExplainer(train_x=train_x, model=dec_tree, class_names=class_names, num_features=6)
log_reg_explainer = ModelExplainer(train_x=train_x, model=log_reg_trained, class_names=class_names, num_features=6)
tree_lime_explainer.explain_one(1120)
log_reg_explainer.explain_one(1120)
log_reg_explainer.instance_idx
log_reg_explainer.explain_one(3)
log_reg_explainer.instance_idx
class ModelExplainer:
    def __init__(self, train_x, model, class_names, num_features):
        self.model = model
        self.train_x = train_x
        self.class_names = class_names
        self.num_features = num_features
        self.lime_explainer = LimeTabularExplainer(self.train_x.values, class_names = self.class_names, feature_names = self.train_x.columns)
        self.instance_idx = None

    def get_exp(self, instance_idx):
        self.exp = self.lime_explainer.explain_instance(self.train_x.values[instance_idx],
                                                       self.model.predict_proba,
                                                       num_features=self.num_features,
                                                       labels=self.class_names)
        self.instance_idx = instance_idx
        return self.exp


    
    def explain_one(self, instance_idx, print_stats=True):
        if self.instance_idx == instance_idx: 
            exp = self.exp
        else:
            exp = self.get_exp(instance_idx)
            return exp


        if print_stats:
            print(f"Explanation for class {self.class_names[0]}")
            print("\n".join(map(str, exp.as_list(label = 0))))
            print("\n")
            print(f"Explanation for class {self.class_names[1]}")
            print("\n".join(map(str, exp.as_list(label = 1))))
            self.instance_idx=instance_idx

    def show_exp(self, instance_idx):
        if self.instance_idx == instance_idx: 
            exp = self.exp 
        else: 
            exp = self.explain_one(instance_idx)
        self.exp.show_in_notebook()

    def evaluate_lime(self, instance_idx):
        if self.instance_idx == instance_idx: 
            exp = self.exp
        else:
            exp = self.get_exp(instance_idx)
            self.instance_idx = instance_idx

        predicted_class = self.model.predict(test_x.values[idx].reshape(1, -1))[0]

        local_explanation = exp.local_exp[predicted_class]
        map_ = exp.as_map()
        x = test_x.values[idx]

        coefs = np.zeros(x.shape[0])

        for v in local_explanation:
            coefs[v[0]] = v[1]

        base = np.zeros(x.shape[0])

        print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
        print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
tree_lime_explainer = ModelExplainer(train_x=train_x, model=dec_tree, class_names=class_names, num_features=6)
log_reg_explainer = ModelExplainer(train_x=train_x, model=log_reg_trained, class_names=class_names, num_features=6)
tree_lime_explainer.explain_one(1120)
class ModelExplainer:
    def __init__(self, train_x, model, class_names, num_features):
        self.model = model
        self.train_x = train_x
        self.class_names = class_names
        self.num_features = num_features
        self.lime_explainer = LimeTabularExplainer(self.train_x.values, class_names = self.class_names, feature_names = self.train_x.columns)
        self.instance_idx = None

    def get_exp(self, instance_idx):
        self.exp = self.lime_explainer.explain_instance(self.train_x.values[instance_idx],
                                                       self.model.predict_proba,
                                                       num_features=self.num_features,
                                                       labels=self.class_names)
        self.instance_idx = instance_idx
        return self.exp


    
    def explain_one(self, instance_idx, print_stats=True):
        if self.instance_idx == instance_idx: 
            exp = self.exp
        else:
            exp = self.get_exp(instance_idx)


        if print_stats:
            print(f"Explanation for class {self.class_names[0]}")
            print("\n".join(map(str, exp.as_list(label = 0))))
            print("\n")
            print(f"Explanation for class {self.class_names[1]}")
            print("\n".join(map(str, exp.as_list(label = 1))))
        return exp


    def show_exp(self, instance_idx):
        if self.instance_idx == instance_idx: 
            exp = self.exp 
        else: 
            exp = self.explain_one(instance_idx)
        self.exp.show_in_notebook()

    def evaluate_lime(self, instance_idx):
        if self.instance_idx == instance_idx: 
            exp = self.exp
        else:
            exp = self.get_exp(instance_idx)
            self.instance_idx = instance_idx

        predicted_class = self.model.predict(test_x.values[idx].reshape(1, -1))[0]

        local_explanation = exp.local_exp[predicted_class]
        map_ = exp.as_map()
        x = test_x.values[idx]

        coefs = np.zeros(x.shape[0])

        for v in local_explanation:
            coefs[v[0]] = v[1]

        base = np.zeros(x.shape[0])

        print("Faithfulness: ", faithfulness_metric(log_reg, x, coefs, base))
        print("Monotonicity: ", monotonicity_metric(log_reg, x, coefs, base))
tree_lime_explainer = ModelExplainer(train_x=train_x, model=dec_tree, class_names=class_names, num_features=6)
log_reg_explainer = ModelExplainer(train_x=train_x, model=log_reg_trained, class_names=class_names, num_features=6)
tree_lime_explainer.explain_one(1120)
log_reg_explainer.explain_one(1120)
log_reg_explainer.instance_idx
tree_lime_explainer.show_exp(1120)
log_reg_explainer.show_exp(1120)
tree_lime_explainer.evaluate_lime(1120)
log_reg_explainer.evaluate_lime(1120)
from model_explainer import ModelExplainer
tree_lime_explainer = ModelExplainer(train_x=train_x, model=dec_tree, class_names=class_names, num_features=6)
log_reg_explainer = ModelExplainer(train_x=train_x, model=log_reg_trained, class_names=class_names, num_features=6)
tree_lime_explainer.explain_one(1120)
log_reg_explainer.explain_one(1120)
tree_lime_explainer.show_exp(0)
log_reg_explainer.show_exp(0)
tree_lime_explainer.evaluate_lime(0)
from model_explainer import ModelExplainer
tree_lime_explainer = ModelExplainer(train_x=train_x, model=dec_tree, class_names=class_names, num_features=6)
log_reg_explainer = ModelExplainer(train_x=train_x, model=log_reg_trained, class_names=class_names, num_features=6)
tree_lime_explainer.explain_one(1120)
log_reg_explainer.explain_one(1120)
tree_lime_explainer.show_exp(0)
log_reg_explainer.show_exp(0)
tree_lime_explainer.evaluate_lime(0)
log_reg_explainer.evaluate_lime(1120)
from model_explainer import ModelExplainer
tree_lime_explainer = ModelExplainer(train_x=train_x, model=dec_tree, class_names=class_names, num_features=6)
log_reg_explainer = ModelExplainer(train_x=train_x, model=log_reg_trained, class_names=class_names, num_features=6)
tree_lime_explainer.explain_one(1120)
log_reg_explainer.explain_one(1120)
tree_lime_explainer.show_exp(0)
log_reg_explainer.show_exp(0)
tree_lime_explainer.evaluate_lime(0)
log_reg_explainer.evaluate_lime(1120)
%load_ext autoreload
%autoreload 2
from model_explainer import ModelExplainer
tree_lime_explainer = ModelExplainer(train_x=train_x, test_x=test_x model=dec_tree, class_names=class_names, num_features=6)
tree_lime_explainer = ModelExplainer(train_x=train_x, test_x=test_x, model=dec_tree, class_names=class_names, num_features=6)
log_reg_explainer = ModelExplainer(train_x=train_x, test_x=test_x, model=log_reg_trained, class_names=class_names, num_features=6)
tree_lime_explainer.explain_one(1120)
log_reg_explainer.explain_one(1120)
tree_lime_explainer.show_exp(0)
log_reg_explainer.show_exp(0)
tree_lime_explainer.evaluate_lime(0)
log_reg_explainer.evaluate_lime(1120)
train_x, train_y = encoded_df[:train_len], dependent_var[:train_len]
test_x, test_y = encoded_df[train_len:], dependent_var[train_len:]

for df in (train_x, train_y, test_x, test_y):
    df.to_json(f"{df}.json")
train_x.__repr__()
train_x.__dir__()
train_x.__name__
train_x, train_y = encoded_df[:train_len], dependent_var[:train_len]
test_x, test_y = encoded_df[train_len:], dependent_var[train_len:]

for df, name in zip((train_x, train_y, test_x, test_y), ('train_x', 'train_y', 'test_x', 'test_y')):
    df.to_json(f"{name}.json")
train_x, train_y = encoded_df[:train_len], dependent_var[:train_len]
test_x, test_y = encoded_df[train_len:], dependent_var[train_len:]

for df, name in zip((train_x, train_y, test_x, test_y), ('train_x', 'train_y', 'test_x', 'test_y')):
    df.to_json(f"{name}.csv")
train_x, train_y = encoded_df[:train_len], dependent_var[:train_len]
test_x, test_y = encoded_df[train_len:], dependent_var[train_len:]

for df, name in zip((train_x, train_y, test_x, test_y), ('train_x', 'train_y', 'test_x', 'test_y')):
    df.to_csv(f"{name}.csv")
encoded_df.to_csv('encoded_df.csv')
dependent_var.to_csv('dependent_var')
%history
%history -f history.txt
